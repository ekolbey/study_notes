\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}

\usepackage{graphicx, url}

\usepackage{amsmath, amsfonts, amssymb, amsthm}
\usepackage{xfrac, mathptmx}

\newcommand{\obj}[1]{{\left\{ #1 \right \}}}
\newcommand{\clo}[1]{{\left [ #1 \right ]}}
\newcommand{\clop}[1]{{\left [ #1 \right )}}
\newcommand{\ploc}[1]{{\left ( #1 \right ]}}

\newcommand{\brac}[1]{{\left ( #1 \right )}}
\newcommand{\induc}[1]{{\left . #1 \right \vert}}
\newcommand{\abs}[1]{{\left | #1 \right |}}
\newcommand{\nrm}[1]{{\left\| #1 \right \|}}
\newcommand{\brkt}[1]{{\left\langle #1 \right\rangle}}
\newcommand{\floor}[1]{{\left\lfloor #1 \right\rfloor}}

\newcommand{\Real}{\mathbb{R}}
\newcommand{\Cplx}{\mathbb{C}}
\newcommand{\Ntrl}{\mathbb{N}}
\newcommand{\Pwr}{\mathcal{P}}
\newcommand{\pr}{\mathbb{P}}
\newcommand{\Ex}{\mathbb{E}}

\newcommand{\defn}{\mathop{\overset{\Delta}{=}}\nolimits}

\usepackage[english, russian]{babel}
\newcommand{\eng}[1]{\foreignlanguage{english}{#1}}
\newcommand{\rus}[1]{\foreignlanguage{russian}{#1}}

\title{Structural analysis and visualization of networks}
\author{Nazarov Ivan, \rus{101мНОД(ИССА)}\\the DataScience Collective}
\begin{document}

\selectlanguage{english}

\maketitle

\begin{description}
	\item[Email] \hfill \\
	lzhukov@hse.ru
	\item[Course webpage] \hfill \\
	\url{http://www.leonidzhukov.net/hse/2015/networks/}
	\url{http://www.leonidzhukov.net/hse/2014/socialnetworks/}
\end{description}

Programming: iPython notebooks
Visualization: yEd, Gephi

Linear algebra prerequisites:
	Spares matrices
	Eigenanalysis


Graph $G=(V,E)$. The set $V$ is the set of vertices and $E$ is a subset of $V\times V$.
An element $(u,v)\in E$ is an edge starting at $u$ and ending in $v$.
The incidence matrix is defined as $a_{ij}=1_E\brac{(i,j)}$, so it denotes and edge $i\to j$.

Random graphs are pure mathematics theory created by Erd\"os and Renyui.
Statistical physics for analysis of complex networks.

Network, social network, complex network just another name for a graph.

Power law (scale free) few vertices with high degree, many nodes with few neighbours.

Complex means that reduction of a system actually destroys the systems.
Cannot predict the whole by the studying the parts.

Facebook network -- many worlds network -- typical for a power law random graph.

Complex networks usually have the following characteristics: \begin{enumerate}
	\item Power law distribution of the vertex degree;
	\item Small diameter and average path length;
	\item High propensity to cluster: the number of triangles in the network.
\end{enumerate}

Let's introduce the following local features of the graph: the vertex degree $\delta^+,\delta^-:V\to \Ntrl$
\begin{align*}
	\delta^+(v) &\defn \#\obj{\induc{u\in V}\, (u,v)\in E }\\
	\delta^-(v) &\defn \#\obj{\induc{u\in V}\, (v,u)\in E }
\end{align*}

``Any two people are on average separated no more than by six intermediate connections.''
\begin{itemize}
\item ``The small-world problem'', Stanley Milgram, 1967
\item ``An experimental study of the small-world problem'', Travers J., Milgram S., 1969
\end{itemize}

Bethe lattice $(V,E)$ is an infinite cycle-free graph with every node having the same number of neighbours $z > 1$.
Given an edge $(v,u)\in E$ the end vertex $u$ is connected to $z-1$ other neighbours, which means that $N_k = N_{k-1}\cdot (z-1)$ with $N_1 = z$, since the centre vertex is connected to $z$ other vertices.
Thus $N_k = z \brac{z-1}^{k-1}$.
And the total number of nodes is \[S_n \defn 1+\sum_{k = 1}^n N_k = 1 + z \frac{\brac{z-1}^n-1}{(z-1)-1}\] (check this!)

For any network $G=(V,E)$ its \textbf{order} is $\abs{V}$ and size is $\abs{E}$.

% As for the format of homework, python + \Latex is acceptable.

% Homework: complete the notebook.!!! -- Completed on 2014-12-17

\section{Lecture \# 2} % (fold)
\label{sec:lecture_2}

THe power law distribution is very natural in the study of networks:
\[p(x) \defn \frac{C}{x^\beta} 1_{\clop{x_0,+\infty}}(x)\]
where $\beta > 0$ is the power.

The indefinite integral of $p(x)$ is equal to
\[\int p(x) dx = \begin{cases}
    C \frac{x^{1-\beta}}{1-\beta},& \text{if } \beta\neq 1\\
    C \ln x, & \text{if } \beta = 1
\end{cases}\]

If $\beta > 1$ then $p(x)$ is a density function and the normalisation constant is determined by
\[\induc{C \frac{x^{1-\beta}}{1-\beta}}^\infty_{x_0} = C \brac{ - \frac{x_0^{1-\beta}}{1-\beta}} = 1\]
whence $C\defn (\beta - 1) x_0^{\beta-1}$. In its final form the density looks like:
\[p(x) \defn \frac{\beta - 1}{x_0} \brac{\frac{x}{x_0}}^{-\beta} 1_{\clop{x_0,+\infty}}(x)\]

The \textbf{survival} function $H(x) = 1 - F(x)$ is useful in network analysis. For the power law the survival function is \[H(x) \defn \brac{\frac{x_0}{x}}^{\beta-1}\]

Median is more suitable for estimating the power law distribution parameters. The quantile function is given by:
\[q_\alpha \defn \brac{1-\alpha}^{-\frac{1}{\beta - 1}} x_0 \]

Power law is scale invariant. Indeed 
\[H(s x) = \brac{\frac{x_0}{s x}}^{\beta - 1} = \brac{s}^{1-\beta} H(x)\]

Consider the node degree distribution of an undirected network.
There will be a majority of nodes with low degree,
and there will be very few vertices with extremely high degree.

Node degree -- the number of nearest neighbours
Degree distribution \[P(k) \defn \frac{n_k}{\sum_{k}n_k}\]
the model is $P(k) = C k^{-\gamma}$.
Normalization -- the Riemann Zeta function.
\[C \sum_{k\geq 1} k^{-\gamma} = 1 \Leftrightarrow C \defn \frac{1}{\zeta(\gamma)}\]

In maximum likelihood vary $x_0$ to get the idea of how $\alpha$ depends on it.

Use Kolmogorov-Smirnov test against the exponential distribution to find the ``best'' values of $x_0$.
Look for the minimal value of the K-S statistic and choose $x_0$.

% read the references

\subsubsection{The maximum likelihood estimation} % (fold)
\label{ssub:the_mle}

Suppose $\brac{x_i}_{i=1}^n$ is an iid sample from some random variable distributed according to the power law.
The log-likelihood is given by \[\log\mathcal{L} = \sum_{k=1}^n \beta \log\frac{x_0}{x_k} + n \log\frac{\beta - 1}{x_0}\]
where $x_0\leq \min_{k=1\ldots n}x_k$, since otherwise the log-likelihood would be $-\infty$.
The first-order conditions are given by \begin{align*}
	- \sum_{k=1}^n \log\frac{x_k}{x_0} + \frac{n}{\beta - 1} = 0\\
	n \brac{ \beta - 1 } \frac{1}{x_0} > 0
\end{align*}

Therefore $\hat{x}_0 \defn \min_{k=1\ldots n}x_k$ and the ML-optimal estimator of $\beta$ is
\[\hat{\beta} \defn 1 + \frac{n}{\sum_{k=1}^n ( \log x_k - \log x_0 )}\]

% subsubsection the_mle (end)

\subsubsection{The OLS estimation} % (fold)
\label{ssub:the_ols_estimation}

Another possibility is to estimate the parameters of the power law by means of a regression of the frequencies of binned sample on the ``typical'' values of the bins.

Suppose $\brac{f_i}_{i=1}^B$ and $\brac{b_i}_{i=1}^B$ are bin frequencies and centres respectively, constructed on data $\brac{x_k}_{k=1}^n$ which supposedly came from a power law distribution.

Then it is possible to fit the following regression model to the histogram data to get the parameters of the law:
since $f_x \sim p(x) \Delta x$
\[\log f_i \sim \brac{\log{(\beta-1)} + (\beta-1) \log x_0} + (-\beta) \log b_i\]
It is a fast but a rather crude way of estimating.

% subsubsection the_ols_estimation (end)

% section lecture_2 (end)

\section{Lecture \# 3} % (fold)
\label{sec:lecture_3}

Grpah models

Erd\"os-Rnyi model

A random graph is a element of the set $\prod_{\omega\in \Pwr_2(V)} \obj{0,1}$.
A large collection of Bernulli random variables, indicating whether an edge is present or not.

$G_{n,m}$ model -- a graph is randomly selected form a set  $C_N^m$ graphs, with $N\defn \frac{n(n-1)}{2}$ of with $n$ nodes and $m$ edges.

$G_{n,p}$ -- the model of a random graph in which an edge between
any two vertices is established with probability $p$. The total
number of edges is again $N$. The size of the graph is a thus a
random number.

The models are asymptotically equivalent.

The mean node degree is given by
\[\epsilon(G) = \frac{2 \Ex(m)}{n} = p\frac{2 n(n-1)}{2 n} \approx p n\]
The graph density is the \[\rho \defn 2\frac{\Ex(m)}{n(n-1)}\]

The degree distribution of a random graph.

The chance that a given node $v$ has $k$ neighbours is given by:
\[\pr\brac{\delta(v) = k} = C^k_{n-1} p^k \brac{1-p}^{n-k-1}\]

Since the binomial distribution is asymptotically poisson if $p n = \lambda$ and $n\to \infty$:
\[C^k_{n-1} p^k \brac{1-p}^{n-k-1} \to \]

Use these models as a benchmark (in the null hypothesis) to compare against the phenomena in the real life.

Treating the model parametrically to witness phase transitions.
\begin{description}
	\item[$p=0$] \hfill \\ the graph is a set of isolated vertices;
	\item[$p=p_c$] \hfill \\ the graph obtains a spanning tree;
	\item[$p=1$] \hfill \\ the graph is totally connected.
\end{description}

Suppose $p$ changes with $n$. 


The chance that a node does not belong the the Giant Connected Component,
in the case of Poisson node degree distribution is given by
\[ u = \sum_{k\geq 0} \pr(k) u^k = \sum_{k\geq 0} e^{-\lambda}\frac{\lambda^k}{k!}u^k = e^{\lambda (u-1)}\]
the necessary condition for a nonzero $u$ is that $\lambda>1$
(ensures that the graph of the exponent intersects the $45\,^{\circ}$ line at a nonzero point).

\begin{description}
	\item[$p\to p_c-$] \hfill \\ no components larger than $O(\log n)$;
	\item[$p=p_c$] \hfill \\ the largest component has $O(n^\frac{2}{3})$;
	\item[$p\to p_c+$] \hfill \\ the gigantic connected component is of the order $O(n)$.
\end{description}
The critical values is $p_c n = 1$.

Threshold values at which interesting phenomena appear -- subgraphs of order $g$:
\begin{description}
	\item[$p\sim n^\frac{-g}{g-1}$] there almost surely exists a tree of order $g$;
	\item[$p\sim n^{-1}$] there is a cyclce of order $g$;
	\item[$p\sim n^\frac{-2}{g-1}$] a clique of order $g$ (a complete subgraph).
\end{description}


The clustering coefficient: ratio of closed triangles to all possible triangles
\[C(k) = \frac{p k(k-1) 2 }{ k( k-1 ) 2} = p\]
The sparser the graph the more negligible is the clustering coefficient.

The average number of nodes $s$ hops away from the current node is $\lambda^s$.
In the critical regime of the edge probability, all nodes belong to the the GCC with high probability.
Thus $d \sim \frac{\log n}{\log \lambda}$.

Fixing the issues with degree distribution.
The configuration model.
Take $V$ vertices and a finite sequence of node degrees $\brac{d_v}_{v\in V}$ with $\sum_{v\in V} d_v$ -- even.

% Slide~17.
The constructed graph might be a lopped multigraph.
Solution: use special graphical degree sequences.
The probability that $v,u\in V$ are connected is given by
\[p_{uv}\frac{d_u d_v}{2 m - 1}\]

Does not allow for an asymptotically non-zero clustering coefficient.

Very different from the Erd\"os-Renyi model!

A random graphs does not have communities.

Non-zero clustering coefficient hint at non-random processes underlying the edge formation.

% section lecture_3 (end)

\section{Lecture \# 4} % (fold)
\label{sec:lecture_4}


% section lecture_4 (end)

\end{document}
