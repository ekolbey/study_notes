{
 "metadata": {
  "name": "",
  "signature": "sha256:dfc15f8d6ae08694f40ecb8a6b07eeed3c021185518eb2e4f92d95151d8090a2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "<center>Structural Analysis and Visualization of Networks</center>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "<center>Home Assignment #1: Power law</center>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "<center>Student: *Nazarov Ivan*</center>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "<hr />\n",
      "General Information"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Due Date:** 28.01.2015 23:59 <br \\>\n",
      "**Late submission policy:** -0.2 points per day <br \\>\n",
      "\n",
      "\n",
      "Please send your reports to <mailto:leonid.e.zhukov@gmail.com> and <mailto:shestakoffandrey@gmail.com> with message subject of the following structure:<br \\> **[HSE Networks 2015] *{LastName}* *{First Name}* HA*{Number}***\n",
      "\n",
      "Support your computations with figures and comments. <br \\>\n",
      "If you are using IPython Notebook you may use this file as a starting point of your report.<br \\>\n",
      "<br \\>\n",
      "<hr \\>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Problems"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Task 1."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load [wordcounts](http://www.leonidzhukov.net/hse/2015/networks/data/wordcounts.txt) dataset. \n",
      "1. Check that Zipf's Law holds\n",
      "2. Assuming that the data is distributed according to the Power Law, find\n",
      " * $\\alpha$ of the distribution\n",
      " * mean sample variance $\\sigma^2$\n",
      "3. Produce summary of the frequencies: min, max, mean, median"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib;\n",
      "import numpy as np;\n",
      "import numpy.linalg as la;\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "plt.style.use( \"ggplot\" )\n",
      "\n",
      "## Define the OLS regression routine:\n",
      "def lm( X, Y, intercept = True):\n",
      "    T = np.asarray( Y )\n",
      "    M = np.asarray( X )\n",
      "    if intercept is True :\n",
      "        M = np.vstack( [ np.ones( len( Y ) ), M ] ).T\n",
      "## (X'X)^{-1} (X'Y)\n",
      "    MMinv = la.inv(\n",
      "        np.dot( M.T, M ) )\n",
      "    coef = np.dot( MMinv,\n",
      "        np.dot( M.T, T ) )\n",
      "## Estimate the residual standard deviation\n",
      "    resid = T - np.dot(M, coef)\n",
      "    dof = len( Y ) - len( coef )\n",
      "    RSS = np.dot( resid.T, resid )\n",
      "    return ((M,T), coef, MMinv, RSS, dof )\n",
      "\n",
      "## Load the wordcount datafile\n",
      "url = urllib.urlopen( \"http://www.leonidzhukov.net/hse/2015/networks/data/wordcounts.txt\" );\n",
      "wc = np.loadtxt( url, dtype = np.dtype( { 'names': ['count','word'], 'formats': [\"f4\", \"<U255\"] } ) );\n",
      "\n",
      "# https://scipy-lectures.github.io/intro/numpy/array_object.html\n",
      "\n",
      "## 1. Check that Zipf's Law holds\n",
      "## Rank the dataset entries by their frequency\n",
      "w_rank = np.empty( len( wc ), int )\n",
      "w_idx = wc.argsort( order = [ 'count', 'word' ] )\n",
      "w_rank[ w_idx ] = np.arange( 1, len( wc ) + 1 )\n",
      "w_freq = wc[ 'count' ][ w_idx ]\n",
      "\n",
      "## Rank-frequency plot in log-log scale\n",
      "plt.figure(1, figsize = ( 10, 10 ) )\n",
      "plt.loglog( w_freq, w_rank, \"+r\" )\n",
      "\n",
      "## The plot clearly shows inverse relation between the\n",
      "##  frequency of a word and the rank in the corpus. It\n",
      "##  would have actually been illogical to expect anything\n",
      "##  else, since, by definition of a rank, the lower the\n",
      "##  frequency the higher the rank.\n",
      "## Zipf's law is f_r \\sim \\frac{1}{r}\n",
      "## The real purpose of this plot is to demonstrate that\n",
      "##  the logarithm of the frequency is inversely proportional\n",
      "##  to the log of the rank. This is clearly seen in the picture.\n",
      "\n",
      "## 2. Assuming that the data is distributed according to the Power Law, find\n",
      "## * $\\alpha$ of the distribution\n",
      "## * mean sample variance $\\sigma^2$\n",
      "## The assumption that the ranks are distributed according to the Power law\n",
      "##  implies that f_r \\sim C r^{-\\gamma}. Therefore the following regression\n",
      "##  model should be estimated:\n",
      "##    \\log f_r = \\log C + (-\\gamma) \\log r\n",
      "model, beta, XX, RSS, dof = lm( np.log( w_rank ), np.log( w_freq ) )\n",
      "t_stat = beta / np.sqrt( RSS * np.diag( XX ) / dof )\n",
      "beta_var = np.sqrt( RSS * np.diag( XX ) / dof )\n",
      "\n",
      "## Display the Confidence Interval for the estimated slope parameter\n",
      "from scipy.stats import t;\n",
      "ci = - ( beta[ 1 ] + np.array( t.interval( 0.95, dof ) )[::-1] * beta_var[ 1 ] )\n",
      "print \"The 95%% confidence interval for the \\\\gamma is (%f, %f)\" % ( ci[0], ci[1] )\n",
      "## The true \\gamma is covered by the computed region region with 95% chance.\n",
      "## In fact it is very likely that the word-generating process, produces output\n",
      "##  which has no second moment.\n",
      "\n",
      "## Compute the sample probabilitites\n",
      "w_prob = w_freq / sum( w_freq )\n",
      "\n",
      "## The sample variance is:\n",
      "print \"The sample varaince \\sigma^2 is %f\" % ( np.dot( w_prob, w_rank**2 ) - np.dot( w_prob, w_rank )**2 )\n",
      "\n",
      "## The disrete power law is : p_k = C k ^{-\\gamma } for all integer k\\geq 1\n",
      "##  The normalisation constant is given by the reciprocal to the Riemann zeta\n",
      "##  function at \\gamma: \\frac{1}{\\sum_{k\\geq 1} k^{-\\gamma}}\n",
      "## In order to estimate the \\gamma properly, let's use a numerical optimization\n",
      "##  routine to maximize\n",
      "##  LOG-Likelihood = - N \\log \\zeta(\\gamma) - \\gamma \\sum_{k\\geq 1} f_k \\log k\n",
      "##  where N = \\sum_{k\\geq 1} f_k.\n",
      "\n",
      "## The log-likelihood function scaled by negative the sum of frequencies:\n",
      "from scipy.special import zeta;\n",
      "mult = np.dot( w_prob, np.log( w_rank ) )\n",
      "nllfn = lambda gamma: np.log( zeta( gamma, 1 ) ) + mult * gamma\n",
      "\n",
      "## Import a univariate optimizer\n",
      "from scipy.optimize import minimize_scalar\n",
      "\n",
      "## Launch the optimization engine!\n",
      "optm_res = minimize_scalar( nllfn, bounds = ( 0.01, 1000 ), method = 'bounded')\n",
      "# print( optm_res )\n",
      "\n",
      "## The regression estimate of the power is close to the ML estimate.\n",
      "print \"the ML estimate of the parameter of the discrete Power law is \\\\gamma = %f\\n\" % optm_res.x \n",
      "print \"the OLS estmiate of the parameter is %f\\n\" % - beta[ 1 ] \n",
      "\n",
      "## Instead of the above lucubrations i could've just used\n",
      "## the following code:\n",
      "# import pandas\n",
      "# from statsmodels.formula.api import ols\n",
      "# data = pandas.DataFrame( { 'l_rank': np.log( w_rank ), 'l_freq': np.log( w_freq ) } )\n",
      "# model = ols( \"l_freq ~ l_rank\", data ).fit( )\n",
      "# print( model.summary( ) )\n",
      "## http://cogmaster-stats.github.io/python-cogstats/basic_statistics.html#linear-models-anova\n",
      "\n",
      "## 3. Produce summary of the frequencies: min, max, mean, median\n",
      "## Does it make sense to compute these summaries?\n",
      "##  What does the mean frequency tell us?\n",
      "print \"The minimum frequency is %f\\n\" % np.min( w_freq )\n",
      "print \"The mean frequency is %f\\n\" % np.mean( w_freq )\n",
      "print \"The median frequency is %f\\n\" % np.median( w_freq )\n",
      "print \"The maximum frequency is %f\\n\" % np.max( w_freq )\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "<hr />\n",
      "Task 2."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Find and plot PDF and CDF for the following networks:\n",
      "* [Routing network](http://www.leonidzhukov.net/hse/2015/networks/data/network.txt)\n",
      "* [Web graph](http://www.leonidzhukov.net/hse/2015/networks/data/web_Stanford.txt)\n",
      "* [Facebook network](http://www.leonidzhukov.net/hse/2015/networks/data/fb_Princeton.txt)\n",
      "\n",
      "\n",
      "1. Are they correspondent to power law?\n",
      "2. Find max and mean values of incoming and outcoming node degrees\n",
      "3. Find $\\alpha$ via Maximum Likelihood and calculate $\\sigma^2$\n",
      "4. Determine $x_{min}$ via Kolmogorov-Smirnov test"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np;\n",
      "import numpy.linalg as la;\n",
      "import networkx as nx;\n",
      "\n",
      "from scipy.stats import kstest;\n",
      "from scipy.special import zeta;\n",
      "from scipy.optimize import minimize;\n",
      "from scipy.stats import t;\n",
      "\n",
      "## This helper function inverts an array\n",
      "def invert_array( data ) :\n",
      "    inv = dict( )\n",
      "    for i, x in enumerate( sorted( data ) ) :\n",
      "        inv[ x ] = [ i ] + inv.get( x, [ ] )\n",
      "    return inv\n",
      "\n",
      "def array_freq( data ) :\n",
      "    inv = invert_array( data )\n",
      "    return zip( inv.keys( ), [ len( v ) for v in inv.values( ) ] )\n",
      "\n",
      "## Define the OLS regression routine:\n",
      "def lm( X, Y, intercept = True):\n",
      "    T = np.array( Y, dtype = float )\n",
      "    M = np.array( X, dtype = float )\n",
      "    if intercept is True :\n",
      "        M = np.vstack( [ np.ones( len( Y ) ), M ] ).T\n",
      "## (X'X)^{-1} (X'Y)\n",
      "    MMinv = la.inv(\n",
      "        np.dot( M.T, M ) )\n",
      "    coef = np.dot( MMinv,\n",
      "        np.dot( M.T, T ) )\n",
      "## Estimate the residual standard deviation\n",
      "    resid = T - np.dot(M, coef)\n",
      "    dof = len( Y ) - len( coef )\n",
      "    RSS = np.dot( resid.T, resid )\n",
      "    return ((M,T), coef, MMinv, RSS, dof )\n",
      "\n",
      "## ML estimator of the power law in the \"tail\":\n",
      "##  x_k \\sim C x^{-\\alpha} 1_{[u,+\u221e)}(x).\n",
      "def mle_alpha_cont( data, threshold ) :\n",
      "    tail = data[ np.ix_( data >= threshold ) ]\n",
      "    sum_log = np.sum( np.log( tail ) ) / len( tail )\n",
      "## Use the closed form expression for the value of the power at an optimum\n",
      "    return 1.0 + 1.0 / ( sum_log - np.log( threshold ) )\n",
      "\n",
      "def ks_dist_cont( data, threshold ) :\n",
      "    alpha = mle_alpha_cont( data, threshold );\n",
      "    cdf = lambda x : return 1 - ( x / threshold ) ** ( 1 - alpha )\n",
      "    return kstest( data[ np.ix_( data >= threshold ) ], cdf )\n",
      "\n",
      "## The discrete power law gives marginally different results\n",
      "##  \\Pr(N=n) \\defn \\frac{1}{\\zeta(\\gamma)} n^{-\\gamma}, n -- positive integer\n",
      "def mle_alpha_discrete( data, threshold ) :\n",
      "    tail = data[ np.ix_( data >= threshold ) ] \n",
      "    sum_log = np.sum( np.log( tail ) ) / len( tail )\n",
      "## minus log-likelihood of the discrete power law\n",
      "    nllfn = lambda gamma : np.log( zeta( gamma, threshold ) ) + gamma * sum_log\n",
      "## Invoke the minimizer statrting at the MLE (for better convergence)\n",
      "    alpha_0 = 1 + 1 / ( sum_log - np.log( threshold ) )\n",
      "    res = minimize( nllfn, (alpha_0,), method = 'Nelder-Mead', options={'disp': False} )\n",
      "## Return the \"optimal\" argument, regardless of its quality. DANGEROUS!\n",
      "    return res.x[ 0 ]\n",
      "\n",
      "def ks_dist_discrete( data, threshold ) :\n",
      "    gamma = mle_alpha_discrete( data, threshold );\n",
      "    cdf = lambda n : zeta( gamma, threshold + n ) / zeta( gamma, threshold )\n",
      "    return kstest( data[ np.ix_( data >= threshold ) ], cdf )\n",
      "\n",
      "import matplotlib.pyplot as plt;\n",
      "%matplotlib inline\n",
      "\n",
      "plt.style.use( \"ggplot\" )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Let's start with the netwrok routing graph \n",
      "G = nx.read_edgelist( \"./data/network.txt\", create_using = nx.DiGraph() );"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 1. Are they correspondent to power law?\n",
      "## Well, to find out the answer to this question, one must,\n",
      "##  first, study the degree versus frequency plot on the log-log\n",
      "##  scale.\n",
      "dd = G.degree( )\n",
      "freq = np.array( array_freq( dd.values( ) ), dtype = (int, float) )\n",
      "prob = np.array( freq[:,1], dtype = float ) / np.sum( freq[:,1] )\n",
      "\n",
      "plt.figure( 1, figsize = ( 5, 5 ) )\n",
      "plt.loglog( freq[:,0], prob, \"ok\" )\n",
      "\n",
      "plt.figure( 2, figsize = ( 5, 5 ) )\n",
      "plt.plot( freq[:,0], np.cumsum( prob ), \"ok\" )\n",
      "\n",
      "## Both the in- and out- degree distributions exhibit linearity\n",
      "##  on the log-log graph.\n",
      "\n",
      "## Let's check if there indeed is linearity\n",
      "model, beta, XX, rss, dof = lm( np.log( freq[1:,0] ), np.log( freq[1:,1] ) )\n",
      "beta_var = np.sqrt( rss * np.diag( XX ) / dof )\n",
      "stat = beta / beta_var\n",
      "print \"degree: exponent is %f (%f)\" % ( -beta[ 1 ], beta_var[ 1 ] )\n",
      "\n",
      "counts, bin_edges = np.histogram( dd.values(), bins= 40, normed=True)\n",
      "cdf = np.cumsum(counts)\n",
      "\n",
      "plt.figure( 3, figsize = ( 5, 5 ) )\n",
      "plt.plot(bin_edges[1:], cdf)\n",
      "plt.title('Outcoming node degree CDF')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum( counts * (bin_edges[1:] - bin_edges[:-1] ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Legacy code to test how discrete and continuous models differ\n",
      "# data = np.array( di.values( ) )\n",
      "# threshold = set( data )\n",
      "# est = np.asarray( zip(\n",
      "#     [ mle_alpha_discrete( data, u ) for u in threshold if u > 0 ],\n",
      "#     [     mle_alpha_cont( data, u ) for u in threshold if u > 0 ] ) )\n",
      "## They do not differ so much as to justify the use of numerical optimization"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = np.sort( np.array( dd.values( ) ) )\n",
      "thresholds = np.unique( data )[1:-5]\n",
      "ks_dist = np.array( [ (u, ks_dist_cont( data, u )) for u in thresholds if u > 0 ], dtype = float )\n",
      "alphas = np.array( [ (u, mle_alpha_cont( data, u )) for u in thresholds if u > 0 ], dtype = float )\n",
      "\n",
      "plt.figure( 3, figsize = ( 10, 6 ) )\n",
      "plt.plot(  alphas[:,0], alphas[:,1], \"kx\")\n",
      "plt.figure( 4, figsize = ( 10, 6 ) )\n",
      "plt.plot( ks_dist[:,0], ks_dist[:,1], \"r-\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 2. Find max and mean values of incoming and outcoming node degrees\n",
      "# 3. Find $\\alpha$ via Maximum Likelihood and calculate $\\sigma^2$\n",
      "# 4. Determine $x_{min}$ via Kolmogorov-Smirnov test\n",
      "\n",
      "# # ## The order of a graph is $|V|$ and the size is $|E|$\n",
      "# print \"The network G is of the order %d. Its size is %d.\" % ( G.order( ), G.size( ) )\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# G = nx.read_edgelist( \"./data/web_Stanford.txt\" );\n",
      "# G = nx.read_edgelist( \"./data/fb_Princeton.txt\" );\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}