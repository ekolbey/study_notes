{
 "metadata": {
  "name": "",
  "signature": "sha256:8b7fa1ea82a2d5a2511dd4e52d8ca3d5eaddaa964501b826e394e1a07be82f3c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "<center>Structural Analysis and Visualization of Networks</center>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "<center>Home Assignment #4: Community Detection Algorithms"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "<center>Student: *Nazarov Ivan*</center>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "<hr />\n",
      "General Information"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Due Date:** 19.03.2015 23:59 <br \\>\n",
      "**Late submission policy:** -0.2 points per day <br \\>\n",
      "\n",
      "\n",
      "Please send your reports to <mailto:leonid.e.zhukov@gmail.com> and <mailto:shestakoffandrey@gmail.com> with message subject of the following structure:<br \\> **[HSE Networks 2015] *Nazarov* *Ivan* HA*4***\n",
      "\n",
      "Support your computations with figures and comments. <br \\>\n",
      "If you are using IPython Notebook you may use this file as a starting point of your report.<br \\>\n",
      "<br \\>\n",
      "<hr \\>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Preamble"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The toolbox includes Numpy for computation, NetworkX for graph manipulation and algorithms, matplotlib for visualization and Scipy.IO for processing matlab objects."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import networkx as nx\n",
      "from matplotlib import pyplot as plt\n",
      "%matplotlib inline\n",
      "from scipy.io import loadmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Problems"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Task 1* (For those who have not done that during the seminar)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On this seminar your are asked to implement simple community detection algorightm. It is called [Markov Cluster Algorithm](http://micans.org/mcl/) (MCL)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Markor Clustering Algorithm  \n",
      "**Input:** Transition matrix $T = D^{-1}A$  \n",
      "**Output:** Adjacency matrix $M^*$  \n",
      "1. Set $M = T$\n",
      "2. **repeat:**\n",
      "    3. *Expansion Step:* $M = M^p$ (usually $p=2$)\n",
      "    4. *Inflation Step:* Raise every entry of $M$ to the power $\\alpha$ (usualy $\\alpha=2$)\n",
      "    5. *Renormalize:* Normalize each row by its sum\n",
      "    6. *Prunning:* Replace entries that are close to $0$ by pure $0$\n",
      "7. **until** $M$ converges\n",
      "8. $M^* = M$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As a result you should get a cluster matrix s.t. elements of the cluster correspont to nonzero elements of the columns of the matrix. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Run this method for network [1](https://www.dropbox.com/s/so0ly2ozh2pzxp6/network1.mat?dl=0), [2](https://www.dropbox.com/s/xcswyhoeehq95v2/network2.mat?dl=0) and [3](https://www.dropbox.com/s/cwshsfr2d8fn470/network3.mat?dl=0).\n",
      "* Play with the parameters ($p$, $\\alpha$, zero tolerance), analyse the results"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Solution"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Though the specification above clearly states the order of operations within each iteration, the algorithm implemented below mpved \"pruning\" to before \"inflation\". First of all this uncovered more straightforward connection of the pruning parameter with transition probability. Secondly, as a side effect the final step within each iteration became \"renormalization\", which produces a row-stocastic matrix for the next iteration.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mcl_iter( A, p = 2, alpha = 2, theta = 1e-8, rel_eps = 1e-4, niter = 10000 ) :\n",
      "## Convert A into a transition kernel: M_{ij} is the probability of making a transition from i to j.\n",
      "    M = np.multiply( 1.0 / A.sum( axis = 1, dtype = np.float64 ).reshape(-1,1), A )\n",
      "    i = 0 ; status = -1\n",
      "    while i < niter :\n",
      "        M_prime = M.copy( )\n",
      "## Expansion step: M_{ij} is the probability of reaching a vertex j from i in p hops.\n",
      "        M = np.linalg.matrix_power( M, p )\n",
      "## Pruning: make paths with low transition probability into almost surely unused.\n",
      "        M[ np.abs( M ) < theta ] = 0\n",
      "## Inflation step: dampen the probabilites\n",
      "        M = np.power( M, alpha )\n",
      "## Renormalisation step: make the matrix into a stochastic transition kernel\n",
      "        N = M.sum( axis = 1, dtype = np.float64 )\n",
      "## If a nan is encountered, then abort\n",
      "        if np.any( np.isnan( N ) ) :\n",
      "            status = -2\n",
      "            break\n",
      "        M = np.multiply( 1.0 / N.reshape(-1,1), M )\n",
      "## Convergence criterion is the L1 norm of relative divergence of transition probabilities\n",
      "        if np.sum( np.abs( M - M_prime ) / ( np.abs( M_prime ) + rel_eps ) ) < rel_eps :\n",
      "            status = 0\n",
      "            break\n",
      "## Advance to the next iteration\n",
      "        i += 1\n",
      "    return ( M, (status, i) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The agorithm is desinged to transform the graph connectivity in such a way as to disconnect different communities and concentrate connectivity within one.\n",
      "\n",
      "At each iteration the algorithm cacluates a new transition kernel, based on the **$p$-hop importance score** $u_{ij}$ of connectivity of nodes $i$ and $j$ in the original kernel.\n",
      "\n",
      "The score is a nonlinear transformation of the $p$-hop connectivity probability $\\pi^p_{sd} = \\mathbb{P}( s\\rightarrow_p d )$, which reflects the chances of reaching any node $d$ from a vertex $s$ in $p$-hops. \n",
      "\n",
      "The procedure consists of \"pruning\" and \"inflation\" steps. At the pruning step, the algorithm zeroes the $p$-hop transition prbabilities lower that a $\\theta$. The rationale is, that if the random walk from $i$ is unlikely to end up in vertex $j$ in $p$ hops, then the $i\\sim j$ path is not likely to connect vertices within one community. Thus the pairs of nodes $(i,j)$ with $p$-hop transition probability $\\pi_{ij}^p$ lower than the threshold are forcefully disconnected. However, if the nodes $i$ and $j$ belong to the same community, the higher is the chance that a random walk reaches $j$ from $i$. Therefore zeroing negligible in effect severs weak between community connections.\n",
      "\n",
      "At next step the remaining non-zero $\\pi_{ij}^p$ are damped by a power transformation with parameter $\\alpha>1$ to get the **importance score** $u_{ij} = \\big(\\pi^p_{ij}  \\big)^\\alpha 1_{\\pi_{ij}^p\\geq \\theta}$. Finally the renormalisation step, makes the scores into one-hop transition probabilities for the next iteration. The a new transition kernel is thus $\\pi_{ij}' \\propto u_{ij}$ with the constraint $\\sum_j \\pi_{ij}' = 1$. The matrix $M$ in the algorithm is a transposed stochastic transition matrix: each entry is the probability $\\pi_{ij} = \\mathbb{P}( i\\rightarrow j )$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Based on this description the following hypothese can be formulated with respect to the effects of the parameters $\\alpha$, $p$ and $\\theta$:\n",
      "* $\\theta\\in(0,1)$ -- determines the level beyond which the path transition probabilities are considered important enough to contibute to a community; A high $\\theta$ makes the detection less sensitive, and beyond some threshold may cause the algorithm to fail to detect anything.\n",
      "* $p\\geq1$ integer: determines how far the periphery of a community may spread. The higher the $p$ the the less sensitive is community detection to the separation of nodes, and the more likely it is to find larger communities.\n",
      "* $\\alpha>1$ real: governs the damping. With high $\\alpha$ highly probable transitions stay probable in the final transition kernel $\\pi_{ij}'$, while moderate become negligible. That is why with low $\\alpha$ larger communities are detected, whereas high damping exponent tends to detect more concentrated, tighter communities, is any at all."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "The higher the $\\theta$ the more important paths are eliminated thereby detecting more concentrated communities. With lower $\\theta$ the algorithm is more likely to find larger communities;"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_communities( M, lengths = True ) :\n",
      "## It is extected that the MCL matrix detects communities in columns\n",
      "    C = list( ) ; i0 = 0\n",
      "    if np.any( np.isnan( M ) ) :\n",
      "        return C\n",
      "## Find all indices of nonzero elements\n",
      "    r, c = np.where( M )\n",
      "## Sort them by the column index and find the community sizes\n",
      "    r = r[ np.argsort( c ) ]\n",
      "    u = np.unique( c, return_counts = True )\n",
      "    if lengths :\n",
      "        return u[ 1 ]\n",
      "## Columns indices of nonzero entries are ordered, so we just need to\n",
      "##  sweep across the sizes\n",
      "    for s in u[ 1 ] :\n",
      "## Row indices for a column with a nonzero element are the indices of\n",
      "##  nodes in the community.\n",
      "        list.append( C, r[ i0:i0+s ] )\n",
      "        i0 += s\n",
      "    return C"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Maybe the all-pars shortest path matrix could yield some insight into the effects of the different parameter settings."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def floyd_warshall( A ) :\n",
      "## Create a matrix object (not just a 2D array -- different broadcasting properties)\n",
      "    pi = np.matrix( A, dtype = np.float, copy = True )\n",
      "## Fill as of yet unreachable vertices\n",
      "    pi[ pi != 1 ] = np.inf\n",
      "## And show that the shortest path to oneself is staying.\n",
      "    np.fill_diagonal( pi, 0 )\n",
      "## For each transitory vertex\n",
      "    for v in xrange( pi.shape[ 0 ] ) :\n",
      "## Decide which is faster: to use a path without it, or to pass through it.\n",
      "        np.minimum( pi, pi[:,v] + pi[v,:], pi )\n",
      "## Return the shortest path matrix\n",
      "    return pi"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's load the first netork and run the MCL community detection procedure with default parameters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Load the first network\n",
      "data = loadmat( './data/hw4/network1.mat' )\n",
      "\n",
      "## Run the MCL\n",
      "A = np.array( data[ 'A' ], np.float )\n",
      "C, (s, n) = mcl_iter( data[ 'A' ] )\n",
      "sz = extract_communities( C )\n",
      "\n",
      "print \"MCL converged in %d iterations.\" % n\n",
      "print \"Found %d communities with sizes:\" % len( sz ), sz\n",
      "\n",
      "## plot the original and the MCL community detection for the default parameters\n",
      "plt.figure( figsize=(16,6) )\n",
      "plt.subplot( 121 )\n",
      "plt.spy( A )\n",
      "plt.title( \"the orginal adjacency matrix\" )\n",
      "plt.subplot( 122 )\n",
      "plt.spy( C )\n",
      "plt.title( \"the community matrix\" )\n",
      "plt.show( )\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### First network"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create $10\\times 15$ grid of $(\\alpha, p)$ pairs, with $\\alpha$ spaced evenly apart from $1$ to $10$, and $p$ running from $1$ to $15$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alpha_grid, p_grid = 2 + np.arange(10), 2 + np.arange( 15, dtype = np.int )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run the MCL for each pair of the parameters in the grid."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%lprun -f mcl_iter [  mcl_iter( A, p = p, alpha = a ) for p in p_grid for a in alpha_grid ]\n",
      "# mcl_res = [ mcl_iter( A, p = p, alpha = a ) for p in p_grid for a in alpha_grid ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<hr />"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Task 2"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load [Yahoo Music network](https://www.dropbox.com/s/o3x14v4rznrh555/music_data.mat?dl=0). Edges in this network appear if enough number of users have given ratings to both music bands. Note, that edges are weighted with similarity of the ratings.\n",
      "\n",
      "* Implement *multilevel spectral recursive partitioning* algorithm that was described during the lecture\n",
      "* Visualize community structure of the network and output some of the dense clusters (with interpretation, if you can)\n",
      "\n",
      "You can load .mat files with the following commands:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import networkx as nx\n",
      "from matplotlib import pyplot as plt\n",
      "%matplotlib inline\n",
      "from scipy.io import loadmat\n",
      "from sklearn.cluster import SpectralClustering"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.io\n",
      "import scipy.sparse as spma\n",
      "import scipy.sparse.linalg as spla\n",
      "\n",
      "data = scipy.io.loadmat('./data/hw4/music_data.mat')\n",
      "A = spma.csc_matrix( data[ 'A' ], dtype = np.float )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets consider a problem of partitioning a  similarity matrix $A=\\big(a_{ij}\\big)_{i,j\\in I}$ in two clusters non overlapping clsuters $A, B\\subseteq I$ with $A\\uplus B = I$. The matrix $A$ is a symmetric matrix of nonnegative elements.\n",
      "\n",
      "The **cut**, or in other words, the between-cluster similarity, is defined as the sum of all edges across the boundary of the partition in a weighted graph with adjacency matrix $A$:\n",
      "$$\\text{cut}(A, B) = \\sum_{i\\in A}\\sum_{j\\in B} a_{ij}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let $u$ be a partition vector with $u_i = +1$ if $i\\in A$ and $-1$ otherwise (if $i\\notin A$, or $i\\in B$). Then the cut can be represented as  \n",
      "$$\\text{cut}(A,B) = \\frac{1}{8} \\sum_{i,j} a_{ij}(u_i-u_j)^2$$\n",
      "since edges are counted twice, and $(u_i-u_j)^2 = 4$ whenever $i,j\\in A$ or $i,j\\in B$, and $0$ otherwise.\n",
      "Furthermore one has\n",
      "\n",
      "$$\\sum_{i,j} a_{ij}(u_i-u_j)^2 = \\sum_{i,j}a_{ij}(u_i^2+u_j^2) - 2\\sum_{i,j}a_{ij}u_iu_j\n",
      "= 2\\Big( \\sum_i u_i^2 \\sum_j a_{ij} - u'Au \\Big)\n",
      "= 2\\Big( \\sum_i u_i \\delta_i u_i - u'Au \\Big) = 2 u'\\big(D-A\\big)u$$\n",
      "\n",
      "where $D=\\text{diag}\\big(\\delta_i\\big)$ and $\\delta_i = \\sum_j a_{ij}$.\n",
      "Now since $u'u = n$, the cut is equivalently given by  \n",
      "$$\\text{cut}(A, B) = \\frac{n}{4} \\frac{u'Lu}{u'u}$$  \n",
      "where the matrix $L = D-A$ is also known as the Laplacian."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Consider a weighted cut criterion:\n",
      "$$\\mathcal{Q}(A,B) = \\frac{\\text{cut}(A,B)}{W_A} + \\frac{\\text{cut}(A,B)}{W_B} = \\frac{W_A + W_B}{W_A W_B}\\text{cut}(A,B)$$\n",
      "where $W_A = \\sum_{i\\in A} \\omega_i$ and $W = \\text{diag}\\big(\\omega_i\\big)$ -- a full rank diagonal matrix."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define a new partition vector $q$ by $q_i = \\sqrt{\\frac{W_B}{W_A}}$ for $i\\in A$ and $q_i = - \\sqrt{\\frac{W_A}{W_B}}$ otherwise. Then\n",
      "$$q'W\\mathbf{1} = \\sum_i q_i \\omega_i = \\sqrt{\\frac{W_B}{W_A}}\\sum_{i\\in A} \\omega_i - \\sqrt{\\frac{W_A}{W_B}}\\sum_j \\omega_j = \\sqrt{W_AW_B}-\\sqrt{W_AW_B}=0$$\n",
      "and\n",
      "$$q'Wq = \\sum_i q_i^2 \\omega_i = \\frac{W_B}{W_A}\\sum_{i\\in A} \\omega_i^2 + \\frac{W_A}{W_B}\\sum_j \\omega_j^2 = W_A + W_B$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, let's express $q$ in terms of $u$:\n",
      "$$q_i = \\frac{W_B}{\\sqrt{W_A W_B}} \\text{ if } i\\in A \\text{ and } q_i = - \\frac{W_A}{\\sqrt{W_A W_B}} \\text{ otherwise}$$\n",
      "Whence the following expression follows:\n",
      "$$q = \\frac{1}{2 \\sqrt{W_A W_B}} \\Big( W_B (u+\\mathbf{1}) + W_A (\\mathbf{1}-u) \\Big)\n",
      "= \\frac{1}{2 \\sqrt{W_A W_B}} \\Big( (W_B+W_A) u + (W_B-W_A) \\mathbf{1} \\Big)$$\n",
      "because  $u_i=+1$ if $i\\in A$ and $u_i=-1$ otherwise."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since $L\\mathbf{1} = D\\mathbf{1} - A\\mathbf{1} = 0$, one the following expresssion is true:\n",
      "$$q'Lq\n",
      "= \\frac{1}{4 W_A W_B} \\Big( (W_B+W_A) u +(W_B-W_A) \\mathbf{1} \\Big)' L \\Big( (W_B+W_A) u +(W_B-W_A) \\mathbf{1} \\Big)\n",
      "= \\frac{(W_B+W_A)^2}{4 W_A W_B} u'L u$$\n",
      "\n",
      "Rearranging:\n",
      "$$\\frac{q'Lq}{q'Wq} = \\frac{W_B+W_A}{W_A W_B} \\frac{u'L u}{4} = \\frac{W_A + W_B}{W_A W_B}\\text{cut}(A,B) = \\mathcal{Q}(A,B)$$\n",
      "\n",
      "This demonstrates that the problem of finding $A,B\\subseteq I$ such that $\\mathcal{Q}(A, B)$ is minimized is equivalent to finding such a partition vector $q$ that the ratio $\\frac{q'Lq}{q'Wq}$ is minimal subject to $q'W\\mathbf{1}=0$ constraint."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The problem\n",
      "\n",
      "$$\\frac{q'Lq}{q'Wq}\\rightarrow \\min_{q\\neq 0} \\text{ subject to } q'W\\mathbf{1} = 0$$\n",
      "\n",
      "for a real valued vector $q$ can easily be solved. Indeed, the Lagrangian of the problem is\n",
      "\n",
      "$$\\mathcal{L} = \\frac{q'Lq}{q'Wq} - 2q'W\\mathbf{1}\\mu \\rightarrow \\min$$\n",
      "\n",
      "yields the **F**irst **O**rder **C**onditions \n",
      "\n",
      "$$\\frac{\\partial}{\\partial q} \\mathcal{L} = \\frac{ 2Lq (q'Wq) - 2Wq (q'Lq) }{(q'Wq)^2} - W'\\mathbf{1} (2\\mu) = 0$$\n",
      "and\n",
      "$$\\frac{\\partial}{\\partial \\mu} \\mathcal{L} = 2q'W\\mathbf{1} = 0$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The FOC for $q$ simplifies to $Lq (q'Wq) - Wq (q'Lq) = W'\\mathbf{1} \\mu (q'Wq)^2$. Left multiplying by $\\mathbf{1}'$ results in\n",
      "\n",
      "$$\\mathbf{1}'Lq (q'Wq) - \\mathbf{1}'Wq (q'Lq) = \\mathbf{1}'W\\mathbf{1} \\mu (q'Wq)^2$$\n",
      "\n",
      "However $\\mathbf{1}'L = 0'$, whence $-\\mathbf{1}'Wq (q'Lq) = \\mathbf{1}'W\\mathbf{1} \\mu (q'Wq)^2$ and the FOC for $\\mu$ finally gives $\\mathbf{1}'W\\mathbf{1} \\mu (q'Wq)^2 = 0$. This implies $\\mu=0$, as $W$ is diagonal with positive values, whence the first order conditions simplify to $Lq = Wq \\lambda$ for $\\lambda = \\frac{q'Lq}{q'Wq}$.\n",
      "\n",
      "Thus solution of the relaxed problem is equivalent to finding a generalsed eigenvector $q$ of $Lq=Wq\\lambda$ corresponfing to the smallest nonzero eigenvalue."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### References:  \n",
      "**Dhillon, I. S.** (2001, August). \"Co-clustering documents and words using bipartite spectral graph partitioning\". In _Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining_ (pp. 269-274). ACM."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cluster( A, T = 100, sort = False ) :\n",
      "## Compute the global similarity of each vertex/element\n",
      "    deg = A.sum( axis = 1 ).getA1( )\n",
      "## Detect non-isolated items\n",
      "    nz, zz = np.where( deg != 0 )[ 0 ], np.where( deg == 0 )[ 0 ]\n",
      "    if len( nz ) < T :\n",
      "        return np.arange( len( deg ) )\n",
      "## This fiddling with tocsr() and tocsc() enables faster slicing.\n",
      "    S = A[:,nz].tocsr()[nz,:].tocsc()\n",
      "## Compute the stochastic transition kernel of non-isolated vertices:\n",
      "##  L = D^{-1} A' = D^{-1} A\n",
      "    D = spma.diags( 1.0 / deg[ nz ], offsets = 0 )\n",
      "    L = D.dot( S )\n",
      "## Compute the Normalized symmetric laplacian:\n",
      "##  L = E - D^{-0.5} A D^{-0.5}\n",
      "    #D = spma.diags( 1.0 / np.sqrt( deg[ nz ] ), 0 )\n",
      "    #L = D.dot( S.dot( D ) )\n",
      "    try :\n",
      "## Find the eigenvector corresponding to the 2nd largerst eigenvalue\n",
      "        l, e = spma.linalg.eigs( L, k = 2 )\n",
      "    except :\n",
      "## Return the gloabl cluster is the eigenvalue computation failed to converge\n",
      "        return np.arange( len( deg ) )\n",
      "## Get the real part of the eigenvector\n",
      "    e = e[ :, np.argmin( l ) ].real\n",
      "#     if e[-1] < 0 : e = -e\n",
      "## Set the threshold: median produces more balanced clusters\n",
      "    t = np.median( e )\n",
      "## Separate the items in two sets: left(n) and right (p)\n",
      "    n, p = np.where( e <= t )[ 0 ], np.where( e > t )[ 0 ]\n",
      "## If there is enough elements in a set, split it.\n",
      "    n = n if len( n ) < T else n[ cluster( A[:,n].tocsr()[n,:].tocsc(), T = T ) ]\n",
      "    p = p if len( p ) < T else p[ cluster( A[:,p].tocsr()[p,:].tocsc(), T = T ) ]\n",
      "## The returned indices reorder the rows and columns of the supplied matrix\n",
      "    if False :\n",
      "        I = np.argsort( e )\n",
      "        p, n = I[ p ], I[ n ]\n",
      "    return np.concatenate( ( nz[ p ], nz[ n ], zz ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%lprun -f cluster cluster( A, T = 10 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "I = cluster( A, T = 10 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_cluster( A, I ) :\n",
      "    S = A[:,I].tocsr()[I,:].tocoo()\n",
      "    fig = plt.figure( figsize = ( 16, 16 ) )\n",
      "    ax = fig.add_subplot( 111, axisbg = 'black' )\n",
      "    ax.plot( S.col, S.row, 'sw', ms = 1 )\n",
      "    ax.set_xlim( 0, S.shape[ 1 ] )\n",
      "    ax.set_ylim( 0, S.shape[ 0 ] )\n",
      "    ax.invert_yaxis()\n",
      "#     ax.set_aspect('equal')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_cluster( A, I )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "G = nx.karate_club_graph()\n",
      "M = nx.to_scipy_sparse_matrix( G, dtype = np.float, format = 'csc' )\n",
      "I = cluster( M, T = 4 )\n",
      "S = M[:,I].tocsr()[I,:].tocsc()\n",
      "plt.spy( S.todense() )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Compute the Normalized symmetric laplacian: L = E - D^{-0.5} A D^{-0.5}\n",
      "D = spma.diags( np.array( 1.0 / np.sqrt( A.sum( axis = 1 ) ) ).ravel( ), 0 )\n",
      "L1 = spma.eye( *A.shape ) - D.dot( A.dot( D ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Compute the ordinary laplacian: L = D - A\n",
      "D = spma.diags( np.array( 1.0 / A.sum( axis = 1 ) ).ravel( ), 0 )\n",
      "L3 = D - A"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}