{
 "metadata": {
  "name": "",
  "signature": "sha256:8232a507f33c84ddfe35630e7cc3e6e8641501fec5426b8c3092b9245e76167b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "<center>Structural Analysis and Visualization of Networks</center>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "<center>Home Assignment #3: Centralities and Assortativity</center>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "<center>Student: *{Your Name}*</center>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "<hr />\n",
      "General Information"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Due Date:** 09.03.2015 23:59 <br \\>\n",
      "**Late submission policy:** -0.2 points per day <br \\>\n",
      "\n",
      "\n",
      "Please send your reports to <mailto:leonid.e.zhukov@gmail.com> and <mailto:shestakoffandrey@gmail.com> with message subject of the following structure:<br \\> **[HSE Networks 2015] *{LastName}* *{First Name}* HA*{Number}***\n",
      "\n",
      "Support your computations with figures and comments. <br \\>\n",
      "If you are using IPython Notebook you may use this file as a starting point of your report.<br \\>\n",
      "<br \\>\n",
      "<hr \\>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Problems"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Task 1"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Compute degree centrality, Pagerank and  HubAuthorities scores for the [flickr](https://www.dropbox.com/s/6c4ybirvffrm2tu/flickr.zip?dl=0) network. \n",
      "\n",
      "Data contains sparse matrix A and list of user names.\n",
      "This is a \u201cdenser\u201d part of the Flickr photo sharing site friendship graph from 2006. Edge direction corresponds to friendship requests (following). Some of the links are reciprocal,others not.  \n",
      "\n",
      "Provide top 50 names in each ranking, compare results\n",
      "\n",
      "You can load .mat files with the following commands:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Comupte the page rank on the row sparse matrix M with the teleportation probability \\beta\n",
      "import numpy as np\n",
      "import numpy.random as rnd\n",
      "import scipy.sparse as spma\n",
      "import scipy.sparse.linalg as spla\n",
      "\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Page Rank\n",
      "The basic idea of Page Rank, though recursive, is to assign each vertex some importance score based on the aggregate importance score of the node connected to in via incoming edges.\n",
      "\n",
      "The PageRank score has the following interpretation: the more likely it is to find a random surfer in a node, the higher is the pagerank of that node. A random surfer is an agent who follows outgoing links randomly. In terms of the random walk process it is the share of time spent at any particular node in the network.\n",
      "\n",
      "Immediately two issues become apparent:\n",
      " * _Dangling vertices_: the vertices with incoming edges only.  \n",
      "   Since the network is finte, the pure random walk process would end up in such a sink node with probility one in finite number of steps; To avoid this, the walker is forced to restart at any node in the graph chosen uniformly at random.\n",
      " * _Clique traps_. This is a generalization of sink vertices:  \n",
      "   once in a completely connected subgraph, the random surfer is unable to leave the subgraph. In this case at any given node the process is allowed with some probability to make a jump to an arbitrary vertex in $G$ chosen uniformly at random.\n",
      "\n",
      "Let $G=(V,E)$ be a directed graph and its incidence matrix be given by $\\big(A_{vu}\\big)_{u,v\\in V}$ where $A_{uv} = 1_{u\\leadsto v}$,  ie. the $u,v$-th element indicates the weight in general, or the existence in particular, of an edge $u\\leadsto v$ between vertices $u,v\\in V$. Let the out degree be defiend as $\\delta^+_i = \\sum_{j\\in V} a_{ij}$.\n",
      "\n",
      "Consider a $1$-order markov chain with trasnition kernel defined as the stochastic version $P$ of the incidence matrix $A$, defiend as\n",
      "$$q_{ij} = \\frac{ a_{ij} }{\\delta^+_i} 1_{\\delta^+_i\\neq 0} +\\frac{1}{|V|} 1_{\\delta^+_i = 0}$$\n",
      "which denotes the probability of a $i\\to j$. This transition kernel already incorporates the uniform correction for the dangilng nodes.\n",
      "\n",
      "Further adjustnet is due. In orther to escape from the clique traps, the trasition distribtuion at each vertex is further smoothed: having selected a particualt edge $i\\to j$ to follow, the process actually moves to the destination node $j$ with probability $\\beta$ and to any vertex in the graph picked at random (including $j$) with probability $1-\\beta$.  \n",
      "\n",
      "Thus the funal Pagerank process transition kernel is given by the following fomrula for the probability of ending up in one step at node $j$ having started at $i$\n",
      "$$p_{ij} = \\beta q_{ij} + (1-\\beta) \\frac{1}{|V|}$$\n",
      "\n",
      "The matrix $p_{ij}$ is in fact row-stochastic, meanin that on each row the values in the columns sum to one. For example if a column vector $(\\pi_i)_{i\\in V}$ is a prior probability distribution of being in vertex $i$, then the posterior probability is $P'\\pi$.\n",
      "\n",
      "Due to Perron-Frobenius theorem for a well behaved stochastic matrix there necessarily exists a stationary probability distribution. The PageRank is this stationary distribution: $P'\\pi = \\pi$ with $\\pi'\\mathbf{1} = 1$. Furhtermore the the largest eigenvalue of $P'$ is exactly $1$, which menas that iterating $\\pi_k = P'\\pi_{k-1}$ would yield a convergent sequence of probability vectors.\n",
      "\n",
      "In general the incidence matrices are quite large in terms of dimensions which actually requires some modification of how exactly the next refinenemt should be constructed:\n",
      "$$\\pi_{k+1}' = \\beta \\pi_k' D^{-1} A + \\big( \\beta \\pi_k'd + 1-\\beta\\big) \\frac{1'}{|V|}$$\n",
      "where $D_{ii} = \\delta^+_i$ is a diagonal matrix. This expression does not require the transpose of the incidence matrix and \n",
      "\n",
      "The relative tolerance convergence criterion is\n",
      "$$\\max_{i\\in V} \\big\\lvert \\pi_{k+1} - \\pi_k\\big\\rvert \\leq \\epsilon|\\pi_k| + \\epsilon^2$$\n",
      "this permits relative error of approximately $\\epsilon$ tolerance for non-zero values of $\\pi_k$, and yet requires higher precision if the value on hte previous step was zero. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### The iterative procedure\n",
      "As have been mentioned eralier the PageRank score is the egienvector of a stochastic matrix corresponding to the unit eigenvalue. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def PageRank_iter( A, beta = 0.85, x0 = None, rel_eps = 1.0E-6, niter = 10000 ) :\n",
      "## Create a teleporation vector\n",
      "    E = np.full( A.shape[ 0 ], 1.0 / A.shape[ 0 ], np.float )\n",
      "## If the initial ranking is not provided us the uniform distribution over the nodes\n",
      "    x0 = np.copy( E ) if x0 is None else x0\n",
      "## Find the normalising constants for each row\n",
      "    out = np.array( A.sum( axis = 1 ), np.int ).flatten( )\n",
      "## Locate the dangling vertices\n",
      "    dan = np.array( out == 0 )\n",
      "##  ... and reset their normalising constant to avoid NANs\n",
      "    out[ dan ] = 1.0\n",
      "## The resulting status of the convergence procedure:\n",
      "##  0 -- convergence within the set relative tolerance\n",
      "##  1 -- exceeded the number of iterations.\n",
      "    status = 1 ; i = 0\n",
      "## First stopping rule: within the specified number of iterations\n",
      "    while i < niter :\n",
      "## The main computational step\n",
      "        x1 = beta * ( x0 / out ) * A + ( beta * np.sum( x0 * dan ) + 1 - beta ) * E\n",
      "## Second stopping rule: within the required tolerance. Correction for \n",
      "##  possible machine zeros in the denominator.\n",
      "        if np.sum( np.abs( x1 - x0 ) / ( np.abs( x0 ) + rel_eps ) ) < rel_eps :\n",
      "            status = 0\n",
      "            break\n",
      "## Proceed to the next iteration\n",
      "        x0 = x1 ; i += 1\n",
      "## return the stationary distribution and the convergence information\n",
      "    return ( x1, { 'convergence': status, 'iterations' : i } )\n",
      "## Some small test cases\n",
      "# T = spma.csc_matrix( [ [ 0,1,1,0], [0,0,1,0], [1,0,0,1], [0,0,0,0] ] )\n",
      "# T = spma.csc_matrix( [ [ 0,1,1,0,0], [0,0,1,0,0], [0,0,0,1,0], [0,0,0,0,1], [1,0,0,0,0] ] )\n",
      "# print PageRank_iter( T, .9, rel_eps = 1e-10 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Hubs and Authorities index\n",
      "\n",
      "The basic idea of this ranking is ...\n",
      "\n",
      "The HITS algorithm preforms the following steps in succession until the convergence criteria are met:\n",
      " * the current authority and hub scores are given by $a_i$ and $h_i$ respectively;\n",
      " * Based on the current scores calculate the next iteration:\n",
      "    * $a_{i+1} = \\alpha A' h_i$\n",
      "    * $h_{i+1} = \\beta A a_{i+1}$\n",
      "\n",
      "This implies that $h_{i+1} = \\alpha \\beta AA' h_i$ which, when re-normalised by its $l_2$-norm, is known to converge to the egienvector of $AA'$ with the largest eigenvalue.\n",
      "Simalrly, $a_{i+1} = \\alpha \\beta A'A a_i$ is the main iterative core, which converges to the eigenvector of $A'A$.\n",
      "\n",
      "The SVD of an $n\\times m$ matrix $A$ of rank $k$ is a decomposition of it into the product $U\\Sigma V'$ with $U$ -- an $n\\times k$ matrix of orthogonal columns, $V$ -- an $m\\times k$ matrix again of orthogonal columns, and a diagonal $k\\times k$ matrix of positive singular values.\n",
      "It is easy to see, that $A'A = V\\Sigma'\\Sigma V'$ and $AA'=U\\Sigma\\Sigma' U'$, whence $A'A V = V\\Sigma'\\Sigma$ and $AA'U = U\\Sigma\\Sigma'$. Therefore the left and the right singular vector are given by the columns of $U$ and $V$ respectively.\n",
      "\n",
      "The HITS algorithm essentially performs power iterations on the pair of matrices $A'A$ and $AA'$ simultaneously. That is why \n",
      ":\n",
      " 1. the authority and the hub scores are the right and the left signular vectors respectively;\n",
      " 2. the algorithm converges to a pair of singular vectors corresponding to the largest singular value.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def HITS_iter( A, xy0 = None, rel_eps = 1.0E-8, niter = 10000 ) :\n",
      "## Initialise to the uniform hub-authority vector\n",
      "    if xy0 is None:\n",
      "        xy0 = np.full( ( 2, A.shape[0] ), 1.0 / np.sqrt( A.shape[0] ), np.float )\n",
      "## A_{ij} is whether there is an edge i\\to j\n",
      "    status = 1 ; i = 0\n",
      "    while i < niter :\n",
      "        xy = xy0.copy( )\n",
      "## Compute the authorities (a' = \\alpha h' A)\n",
      "        xy[1] = xy[0] * A\n",
      "        xy[1] /= np.linalg.norm( xy[1] )\n",
      "## and the hubs score (h = \\beta A a)\n",
      "        xy[0] = A * xy[1]\n",
      "        xy[0] /= np.linalg.norm( xy[0] )\n",
      "        if np.sum( np.abs( xy - xy0 ) / ( np.abs( xy0 ) + rel_eps ) ) < rel_eps :\n",
      "            status = 0\n",
      "            break\n",
      "        xy0 = xy ; i += 1\n",
      "    return ( xy, { 'convergence': status, 'iterations' : i } )\n",
      "# A = spma.csc_matrix( [ [ 0,1,1,0,0], [0,0,1,0,0], [0,0,0,1,0], [0,0,0,0,1], [1,0,0,0,0] ], dtype = np.float )\n",
      "# ha, _ = HITS_iter( A )\n",
      "# h, _, a = spma.linalg.svds( A, 1 )\n",
      "# h = np.abs( np.array( h ).flatten( ) )\n",
      "# a = np.abs( np.array( a ).flatten( ) )\n",
      "# print np.sum( np.abs(ha[0]-h)/( np.abs( h ) + 1e-8) )\n",
      "# print np.sum( np.abs(ha[1]-a)/( np.abs( a ) + 1e-8) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<hr/>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.io\n",
      "data = scipy.io.loadmat('./data/flickr.mat')\n",
      "\n",
      "## Convert the matrix into a stochastic matrix\n",
      "A = spma.csc_matrix( data['A'] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y1 = PageRank_iter( A, rel_eps = 1e-8 )\n",
      "y1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def PageRank_inver( M, beta ) :\n",
      "    S = spma.coo_matrix( M )\n",
      "## Create a teleporation vector\n",
      "    U = np.full( S.shape[ 1 ], ( 1.0 - beta ) / S.shape[ 1 ], np.float )\n",
      "    S = spma.identity( M.shape[ 1 ], dtype = np.float ) - beta * S\n",
      "    x = spla.spsolve( S, U )\n",
      "    del S\n",
      "    return x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# N = np.matrix( [ [ .3, .4, .3 ], [ 0, .5, .5 ], [ .5, 0, .5 ] ], np.float ).T\n",
      "# N.sum(axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y1 = PageRank_iter( A, .991, rel_eps = 1e-8 )\n",
      "y2 = PageRank_iter( A, .991, rel_eps = 1e-4 )\n",
      "y3 = PageRank_iter( A, .991, rel_eps = 1e-6 )\n",
      "y4 = PageRank_iter( A, .991, rel_eps = 1e-4 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print y1\n",
      "print y2\n",
      "print y3\n",
      "print y4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure( figsize = (16,9) )\n",
      "plt.plot( y1[0]-y4[0], \"y-\" )\n",
      "# plt.plot( y2[0], \"r-\" )\n",
      "# plt.plot( y3[0], \"b-\" )\n",
      "# plt.plot( y4[0], \"k-\" )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PageRank_inver( A, .85 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "<hr />\n",
      "Task 2"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here are the [Facebook friendship graphs](https://www.dropbox.com/s/l4z8x81a9bolpw5/universities.zip?dl=0) from several US universities from 2005 (one year after fb launch).\n",
      "\n",
      "Data contains a A matrix (sparse) and a \"local_info\" variable, one row per node: \n",
      "a student/faculty status flag, gender, major, second major/minor (if applicable), dorm/house, year, and high school. \n",
      "Missing data is coded 0.\n",
      "\n",
      "Compute node degree assortativity (mixing by node degree) and assortativity coefficient (modularity) for gender, major, dormitory, year, high school for all universities and compare the results."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}