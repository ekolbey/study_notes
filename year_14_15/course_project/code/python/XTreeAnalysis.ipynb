{
 "metadata": {
  "name": "",
  "signature": "sha256:97acf1dc3ffef5dcb3120a5dc7e4cbff1fc9a2bb96131e7ee250fb6ed9c40a5e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Crossing times\n",
      "Suppose ${( t_i, x_i)}^N_{k=1}$ is a sample of some continuous process ${( X_t )}_{t\\in T}$ where $X_i = X(t_i)$.<!--, with $T\\subseteq \\mathbb{R}$ an inteval.-->\n",
      "\n",
      "The crossing times are defined as follows: for a given base grid spacing $\\delta>0$ and for $n,k\\geq0$ they are the stopping times $$T^n_{k+1} = \\inf\\Big\\{ t > T^n_k\\,: \\, \\big | X_t - X_{T^n_k} \\big | \\geq \\delta 2^n \\Big\\}$$ with $T^n_0 = 0$. The forcing of the zero-th xcrossing time to $0$ is done to align the grid with the process, so in effect, without losss of generality we may consider processes, which start at the origin.\n",
      "\n",
      "The parameter $\\delta$ is the spacing of the finest grid, with respect to which the leaves of the crossing tree are computed. Parent nodes of these leaves represent crossings of a coraser grid, namely $2\\delta$. The choice of $\\delta$ affects the tree in the following way in the case of a sampled process:\n",
      "**_THIS SECTION MUST BE DISCUSSED_**\n",
      "1. The grid with too low a value of $\\delta$ would be crossed by straight line segments between each pair consecutive sample observations. This could poison the distribution with some unfavouralbe yet unknown mixture and lead to excessive number of seemingly meaningless crossings.\n",
      "2. Too large $\\delta$ lead to a very poor and under sampled crossing tree.\n",
      "\n",
      "By construction, for a binary crossing grid, $N^l_k$, the number of subcrossings in any complete crossing between $T^l_k$ and $T^l_{k+1}$ is always an even number. This is due to the fact, that each crossing is registered as soon as two unidirectional subcrossings are encoutered, as seen by the following.\n",
      "\n",
      "Suppose $T^{n+1}_k$ and $T^n_m$ are aligned in that $T^{n+1}_k=T^n_m$, and $T^{n+1}_{k+1}<+\\infty$, i.e. the $n+1$ grid crossing is complete. First of all $T^n_{m+1},T^n_{m+2}\\leq T^{n+1}_{k+1}$, since otherwise the process would have crossed left the $\\pm\\delta 2^n$ band before it left the $\\pm \\delta 2^{n+1}$ band, which is twice as wide.\n",
      "\n",
      "The process is continuous which means that almost surely for any $\\epsilon>0$ there is $\\eta>0$ such that for any $t$ with $\\big|t-T^n_{m+1}\\big| < \\eta$ it holds that $\\big |X_{T^n_{m+1}}-X_t\\big|<\\epsilon$.\n",
      "Also for every $t\\in\\big[T^n_k, T^n_{k+1}\\big)$ it cannot be otherwise but $\\big | X_t - X_{T^n_k} \\big | < \\delta 2^n$. \n",
      "In particular, for $\\epsilon = \\frac{1}{2}\\delta 2^n$ it means that for a small while after $T^n_{m+1}$ the process is almost surely still within the $\\pm \\delta 2^{n+1}$ band. Therefore $T^n_{m+1} < T^{n+1}_{k+1}$.\n",
      "\n",
      "Thus it is true that $$1\\leq \\bigg | \\frac{1}{\\delta 2^n} \\big(X_{T^n_{m+1}} - X_{T^n_m}\\big)\\bigg | < 2$$. The next crossing of $\\pm\\delta 2^n$ takes palce at $T^n_{m+2}$ and there are two possibilities:\n",
      "1. the process crossed a new $\\pm\\delta 2^{n+1}$ grid line: $\\big|X_{T^n_{m+2}} - X_{T^n_m}\\big|\\geq 2\\cdot\\delta 2^n$. In this case $T^{n+1}_{k+1}\\leq T^n_{m+2}$ and there are _two_ subcrosings.\n",
      "2. the process moved back to the level $X_{T^n_m}$, which does not incurr a crossing of $\\pm\\delta 2^{n+1}$ grid line, yet is registered by the $\\pm\\delta 2^n$ grid. In this case $T^n_{m+2} < T^{n+1}_{k+1}$ and $X_{T^n_{m+2}} = X_{T^{n+1}_{k+1}}$ -- back to the beginning of this argument.\n",
      "\n",
      "Since the crossing is complete, $T^{n+1}_{k+1}<+\\infty$ implies that sooner that later a crossing of $\\pm\\delta 2^{n+1}$ grid occurs, in which case $T^{n+1}_{k+1}=T^n_{m+2p}$, meaning that there were exactly $2p$ subcrossings."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "%matplotlib inline\n",
      "\n",
      "from synthfbmcircul import synth_fbm\n",
      "from hsssi_processes import *\n",
      "from Weierstrass import synth_Weier\n",
      "\n",
      "from crossing_tree import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Distribution checking\n",
      "Let's test the hypothesis that the number of subcrossings follows a distribution similar to geometric. If $G$ is a geometrically distributed random variable, $G\\sim \\text{Geom}(\\theta)$, then $\\mathbb{P}(G=k) = {(1-\\theta)}^{k-1}\\theta$ for any $k\\geq1$, its expectation is $\\mathbb{E}(G) = \\theta^{-1}$.\n",
      "\n",
      "To reiterate, we test the hypothesis that $2N\\sim \\text{Geom}(\\theta)$. Since it is not knon beforehand how much subcrossings there will be in any realisation of the crossing tree, we estimate a truncated geometric distribution: for $k=1\\ldots\\bar{k}$ $$\\mathbb{P}(N=k) = {(1-\\theta)}^{k-1}\\theta\\,1_{k<\\bar{k}} + {(1-\\theta)}^\\bar{k}\\,1_{\\bar{k}\\leq k}$$\n",
      "with an atypical for geometric distributons concentration of probability at the upper truncation level $\\bar{k}$.\n",
      "\n",
      "Since, as has been shown before, the numbers of subcrossings are always even, the distribution of interest in our case becomes\n",
      "$$\\mathbb{P}(N=k) = {(1-\\theta)}^{\\tfrac{k}{2}-1}\\theta\\,1_{k<\\bar{k}} + {(1-\\theta)}^\\tfrac{\\bar{k}}{2}\\,1_{\\bar{k}\\leq k}$$ for $k=2,4,\\ldots\\bar{k}$.\n",
      "\n",
      "Given a sample ${(g_i)}_{i=1}^N$ of a geometrically distributed random variable truncated by some $\\bar{k}$, it is easy to show that the ML extimator of the probability parameter $\\theta$ is given by $$\\hat{\\theta} = \\frac{N-\\#{\\big\\{\\left.i\\,\\right\\rvert\\,g_i=\\bar{k}\\big\\}} }{\\sum_{i=1}^N g_i}$$\n",
      "\n",
      "Indeed the likelihood function is given by $$\\text{LogLik} = \\sum_{v\\in V,v\\neq \\bar{k}} f_v\\frac{v}{2} \\ln {(1-\\theta)} - \\sum_{v\\in V,v\\neq \\bar{k}} f_v \\ln {(1-\\theta)} + \\sum_{v\\in V,v\\neq \\bar{k}} f_v \\ln \\theta + f_{\\bar{k}}\\frac{\\bar{k}}{2} \\ln {(1-\\theta)}$$ where $V$ is the set of all unique values in the sample and $f_v = \\#{\\left\\{\\left.i\\,\\right\\rvert\\,g_i=v\\right\\}}$ -- the number of observations with taking the value specified. Straight forward differentiation yields the desired estimate.\n",
      "\n",
      "The first order condition on optimal $\\theta$, obtained by equating th first derivative of the log-likelihood with respect to the parameter $\\theta$ to zero, are given by\n",
      "$$\\frac{1}{\\theta}\\sum_{v\\in V,v\\neq \\bar{k}} f_v = \\frac{1}{1-\\theta}\\Big(\\frac{1}{2}\\sum_{v\\in V} v f_v - \\sum_{v\\in V,v\\neq \\bar{k}}f_v\\Big)$$\n",
      "using the fact that the frequencies sum up to the the total number of observations $N$ we get\n",
      "$$\\frac{1}{\\theta}(N-f_{\\bar{k}}) = \\frac{1}{1-\\theta}\\Big(\\frac{1}{2}M - (N-f_{\\bar{k}})\\Big)$$\n",
      "where $M = \\sum_{v\\in V} v f_v$ is the sum of all observed values in the sample.\n",
      "Therefore after minor simplification we get $$\\frac{1}{\\theta} = \\frac{1}{2}\\frac{M}{N-f_{\\bar{k}}}$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Given the agregated value-count data in X, compute the MLE of \\theta of the geometric distribution.\n",
      "def mle_theta( x ) :\n",
      "    S = sum( [ i*f for i,f in enumerate( x, 1 ) ] )\n",
      "    N = sum( x )\n",
      "    return (N - x[-1])/S"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####The Monte Carlo routine\n",
      "The procedure below is performs the specified $M$ number of MonteCralo simulations of the sample paths of the process specified by the generator object. The paratmeters $K$ and $T$ determine the truncation performed while collecting the crossing tree data.  \n",
      "For example $K=4$ menas that subcrossings of size up to and including 4 are recorded in full detail, while every subcrossing of larger size is agregated and stored in the ``tail''.  \n",
      "Similarly for the parameter $T$, which set the threshold level of the crossing tree starting from the leaf level and up, beyond which the data is strored in aggregate manner."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def monte_carlo( generator, M = 100, K = 4, T = 2 ) :\n",
      "## K is the maximal number of subcrossings beyond which the data\n",
      "##  on subcrossings is agregateed into the tail. (truncation parameter)\n",
      "\tK = 2 * ( K // 2 + 1 )\n",
      "## T is the number of detailed levels of the crossing tree to stored in\n",
      "##  output. Any crossings of grids coarser than the treshold are\n",
      "##  aggregated.\n",
      "\tdistr = np.zeros( ( K // 2, T + 1, M ), dtype = np.int32 )\n",
      "## The output of the ChSquared independence test\n",
      "# \tchisq = np.empty( ( ) )\n",
      "\tfor m in xrange( M ) :\n",
      "\t\tif m % ( M // 10 ) == 0 : print \"%d \" % ( m, )\n",
      "## Generate a replication of the process\n",
      "\t\tt, x = generator( )\n",
      "## Get the hitting times and poitns\n",
      "\t\tht, hp, subx = xtree_build( t, x )\n",
      "## Run the chi_square test on each level of the tree\n",
      "# \t\tct = ctable( subx[ :-1 ], subx[ 1: ] )\n",
      "##\t\tchisq_test( ct )\n",
      "## Pool together the second and the third layer subcrossings\n",
      "\t\tpool = []\n",
      "\t\tfor level, xing in enumerate( subx[1:], 0 ) :\n",
      "## Count the absolute frequencies\n",
      "\t\t\tc, f = np.unique( xing, return_counts = True )\n",
      "## We collect the data on the distribution truncated by K (including).\n",
      "## Thus truncate the number of subcrossings by K -- everything less is\n",
      "##  detailed, otherwise -- agregated into tail\n",
      "\t\t\tc = np.minimum( c, K )\n",
      "## Similarly truncate the level by T + 1\n",
      "\t\t\tif level >= T : level = T\n",
      "## Fill the offspring distribution matrix\n",
      "\t\t\tfor c, f in zip( c, f ) :\n",
      "\t\t\t\tdistr[ c//2-1, level, m ] += f\n",
      "## Use straightforward bivariate regression implementation.\n",
      "## We could also use ML estimators, which is much better!\n",
      "## See the handwritten notes.\n",
      "## Distr is KxTxM\n",
      "\treturn distr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Simulation results\n",
      "Below interspersed with the listings of code are the results obtained so far for the corssing tree monte carlo simulation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N = 2**20\n",
      "H = .5\n",
      "## First initalize the generator of the desired continuous process\n",
      "genr = synth_fbm( N, H )\n",
      "\n",
      "DD = monte_carlo( genr, M=10, K = 16, T = 3 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DD[:,:,0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "theta = np.apply_along_axis(mle_theta, 0, DD)\n",
      "mle_theta(DD[:,0,0])\n",
      "# [2.0*i*f for i,f in enumerate(x,1)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot( theta[0,:], \"r-\")\n",
      "plt.plot( theta[1,:], \"b-\")\n",
      "plt.plot( theta[2,:], \"k-\")\n",
      "N = 2**20\n",
      "H = .5\n",
      "1/(1-np.log(np.mean(theta[3,:]))) - 2**(1.-1.0/H)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##### Straighforward, dumb linear regression\n",
      "However, for the estimation purposes it is useful to worj with the complementary CDF, instead of the ``density'' itself:\n",
      "$$\\mathbb{P}(N\\geq k) = {(1-\\theta)}^k$$ this way no distinction between $k<\\bar{k}$ of $k=\\bar{k}$ needs to be done.\n",
      "\n",
      "For this purpose, let's estimate the following regression model: $$\\ln \\hat{p}_k \\sim C + \\beta k$$ where $\\hat{p}_k$ is the empirical probability that a crossing had no less than $k$ subcrossings and $\\beta = \\ln \\sqrt{(1-\\theta)}$.\n",
      "\n",
      "It is entirely posible that the distribution's shape depend on the depth. If it does, then there is no self similarity."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import chi2_contingency as chisq_test\n",
      "def ctable( x, y ) :\n",
      "## This procedure makes a contingeny table out of x and y (they should be discrete)\n",
      "    lxy = np.append( x, y ).reshape( len( x ),2)\n",
      "    lxy = lxy.view(dtype = np.dtype([('x', x.dtype), ('y', y.dtype)]))\n",
      "    lc, lf = np.unique( lxy, return_counts = True )\n",
      "    print lc\n",
      "    xc = np.unique( x ) ; yc = np.unique( y )\n",
      "    txy = np.zeros( ( len( xc ), len( yc ) ), dtype = np.int )\n",
      "    vix = lc.view( ( np.int, len( lc.dtype ) ) )\n",
      "    ix = np.searchsorted( xc, vix[:,0] )\n",
      "    iy = np.searchsorted( yc, vix[:,1] )\n",
      "    txy[[ix, iy]] = lf\n",
      "    return txy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Testing on the deterministic cascade"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# scaffolding_plot( *genr( ) )\n",
      "def run() :\n",
      "    monte_carlo( genr, M=100, K = 16, T = 3 )\n",
      "%lprun -f xtree_integer_crossings_fast run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plt.plot(d[0,:], \"rx\", d[1,:], \"bx\", d[2,:], \"kx\")\n",
      "# f ~ a^(k-1)(1-a)\n",
      "# l\n",
      "plt.plot( range(2, 13, 2), np.log(np.mean( d, 1 )) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m = 0\n",
      "for s in a[1:]:\n",
      "    plt.step( s[0], np.log( s[1] * 2**m ), \"b-\")\n",
      "    m+=1\n",
      "plt.step( a[1][0], np.log( a[1][1] ), \"r-\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N = 2**10\n",
      "H = .5\n",
      "\n",
      "# draw(synth_fbm( N, H ))\n",
      "# draw(synth_Weier( N, H ))\n",
      "# draw(synth_Rosenblatt( N, H ))\n",
      "# draw(synth_Hermite3( N, H ))\n",
      "# draw(synth_Hermite4( N, H ))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Test the process generators\n",
      "def draw( gen, seed = None ) :\n",
      "\tt, u = gen( seed )\n",
      "\tt, v = gen( seed )\n",
      "\tplt.plot( t, u, \"r-\", t, v, \"b-\" )\n",
      "\tplt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Last test"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def scaffolding_plot( t, x ) :\n",
      "    ht, hp, xt = xtree_build( t, x )\n",
      "    l = len( ht ) - 5\n",
      "    plt.figure( figsize = (15, 8) )\n",
      "    plt.plot( t, x, \"y-\")\n",
      "# for p in tp[l] : plt.axhline( p, linewidth = 1, color = 'k' )\n",
      "    plt.step( ht[l+0], hp[l+0], \"g>\" )\n",
      "    plt.step( ht[l+1], hp[l+1], \"b>\" )\n",
      "    plt.step( ht[l+2], hp[l+2], \"r>\" )\n",
      "    plt.step( ht[l+3], hp[l+3], \"k>\" )\n",
      "    plt.show( )\n",
      "#     return [zip(*np.unique( x, return_counts = True)) for x in xt ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Weierstrass import *\n",
      "N = 2**15\n",
      "# T, X = genr()\n",
      "T, X = synthweier( N, 0.7, 1.2, 1000, deterministic = True, seed = None )\n",
      "T = np.arange(N, dtype=np.float)/ (N-1)\n",
      "\n",
      "delta = np.std( np.diff( X ), ddof = 1 )\n",
      "Z = ( X - X[ 0 ] ) / delta\n",
      "delta\n",
      "lht, lhp, lhx = xtree_integer_crossings_fast( T, Z )\n",
      "\n",
      "print len(lht), len(lhp)\n",
      "lhp[ np.append( [False], lhp[1:]==lhp[:-1]) ]\n",
      "print len(T), len(Z)\n",
      "np.std( np.diff( lht ), ddof = 1 )-5.3e-05\n",
      "scaffolding_plot( T, X )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ht, hp, hx = xtree_integer_crossings( T, Z )\n",
      "print np.max(np.abs(ht-lht))+np.max(np.abs(hp-lhp))\n",
      "lht, lhp, lhx = xtree_super_crossing( lht, lhp, 2 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}